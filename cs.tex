\documentclass[10pt,landscape,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning,arrows,fit,calc,graphs,graphs.standard}
\usepackage[nosf]{kpfonts}
\usepackage[t1]{sourcesanspro}
%\usepackage[lf]{MyriadPro}
%\usepackage[lf,minionint]{MinionPro}
\usepackage{multicol}
\usepackage{wrapfig}
\usepackage[top=0mm,bottom=1mm,left=0mm,right=1mm]{geometry}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{microtype}

\let\bar\overline

\definecolor{myblue}{cmyk}{1,.72,0,.38}

\def\firstcircle{(0,0) circle (1.5cm)}
\def\secondcircle{(0:2cm) circle (1.5cm)}

\colorlet{circle edge}{myblue}
\colorlet{circle area}{myblue!5}

\tikzset{filled/.style={fill=circle area, draw=circle edge, thick},
    outline/.style={draw=circle edge, thick}}
    
\pgfdeclarelayer{background}
\pgfsetlayers{background,main}

\everymath\expandafter{\the\everymath \color{myblue}}
\everydisplay\expandafter{\the\everydisplay \color{myblue}}

\renewcommand{\baselinestretch}{.8}
\pagestyle{empty}

\global\mdfdefinestyle{header}{%
linecolor=gray,linewidth=1pt,%
leftmargin=0mm,rightmargin=0mm,skipbelow=0mm,skipabove=0mm,
}

\newcommand{\header}{
\begin{mdframed}[style=header]
\footnotesize
\sffamily
Cheat sheet\\
by Cole Rottenberg,~page~\thepage~of~2
\end{mdframed}
}

\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {.2ex}%
                                {.2ex}%x
                                {\color{myblue}\sffamily\small\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{1}{0mm}%
                                {.2ex}%
                                {.2ex}%x
                                {\sffamily\bfseries}}

\def\multi@column@out{%
   \ifnum\outputpenalty <-\@M
   \speci@ls \else
   \ifvoid\colbreak@box\else
     \mult@info\@ne{Re-adding forced
               break(s) for splitting}%
     \setbox\@cclv\vbox{%
        \unvbox\colbreak@box
        \penalty-\@Mv\unvbox\@cclv}%
   \fi
   \splittopskip\topskip
   \splitmaxdepth\maxdepth
   \dimen@\@colroom
   \divide\skip\footins\col@number
   \ifvoid\footins \else
      \leave@mult@footins
   \fi
   \let\ifshr@kingsaved\ifshr@king
   \ifvbox \@kludgeins
     \advance \dimen@ -\ht\@kludgeins
     \ifdim \wd\@kludgeins>\z@
        \shr@nkingtrue
     \fi
   \fi
   \process@cols\mult@gfirstbox{%
%%%%% START CHANGE
\ifnum\count@=\numexpr\mult@rightbox+2\relax
          \setbox\count@\vsplit\@cclv to \dimexpr \dimen@-1cm\relax
\setbox\count@\vbox to \dimen@{\vbox to 1cm{\header}\unvbox\count@\vss}%
\else
      \setbox\count@\vsplit\@cclv to \dimen@
\fi
%%%%% END CHANGE
            \set@keptmarks
            \setbox\count@
                 \vbox to\dimen@
                  {\unvbox\count@
                   \remove@discardable@items
                   \ifshr@nking\vfill\fi}%
           }%
   \setbox\mult@rightbox
       \vsplit\@cclv to\dimen@
   \set@keptmarks
   \setbox\mult@rightbox\vbox to\dimen@
          {\unvbox\mult@rightbox
           \remove@discardable@items
           \ifshr@nking\vfill\fi}%
   \let\ifshr@king\ifshr@kingsaved
   \ifvoid\@cclv \else
       \unvbox\@cclv
       \ifnum\outputpenalty=\@M
       \else
          \penalty\outputpenalty
       \fi
       \ifvoid\footins\else
         \PackageWarning{multicol}%
          {I moved some lines to
           the next page.\MessageBreak
           Footnotes on page
           \thepage\space might be wrong}%
       \fi
       \ifnum \c@tracingmulticols>\thr@@
                    \hrule\allowbreak \fi
   \fi
   \ifx\@empty\kept@firstmark
      \let\firstmark\kept@topmark
      \let\botmark\kept@topmark
   \else
      \let\firstmark\kept@firstmark
      \let\botmark\kept@botmark
   \fi
   \let\topmark\kept@topmark
   \mult@info\tw@
        {Use kept top mark:\MessageBreak
          \meaning\kept@topmark
         \MessageBreak
         Use kept first mark:\MessageBreak
          \meaning\kept@firstmark
        \MessageBreak
         Use kept bot mark:\MessageBreak
          \meaning\kept@botmark
        \MessageBreak
         Produce first mark:\MessageBreak
          \meaning\firstmark
        \MessageBreak
        Produce bot mark:\MessageBreak
          \meaning\botmark
         \@gobbletwo}%
   \setbox\@cclv\vbox{\unvbox\partial@page
                      \page@sofar}%
   \@makecol\@outputpage
     \global\let\kept@topmark\botmark
     \global\let\kept@firstmark\@empty
     \global\let\kept@botmark\@empty
     \mult@info\tw@
        {(Re)Init top mark:\MessageBreak
         \meaning\kept@topmark
         \@gobbletwo}%
   \global\@colroom\@colht
   \global \@mparbottom \z@
   \process@deferreds
   \@whilesw\if@fcolmade\fi{\@outputpage
      \global\@colroom\@colht
      \process@deferreds}%
   \mult@info\@ne
     {Colroom:\MessageBreak
      \the\@colht\space
              after float space removed
              = \the\@colroom \@gobble}%
    \set@mult@vsize \global
  \fi}

\makeatother
\setlength{\parindent}{0pt}

\begin{document}

\header

\begin{multicols}{5}

\section*{Supervised Classification}
\subsection*{Boosting}
\subsubsection*{AdaBoosting}
\begin{itemize}
  \item \textbf{Weight Assignment:} $w_{i,0} = \frac{1}{n}$
  \item \textbf{Error Rate:} $r_j = \frac{\sum\limits_{\substack{i=1 \\ \hat{y}_j^{(i)}\neq y^{(i)}}}^N w^{(i)}}{\sum_{i=1}^N w^{(i)}}$
  \item Predictor Weight: $\alpha_j = \eta \ln \left(\frac{1-r_j}{r_j}\right)$
\end{itemize}

\subsection*{Hard SVM}
\begin{itemize}
  \item $y(x) = w^T \phi(x) + b = 0$
  \item \textbf{Margin:} $\frac{1}{\|w\|}$
  \item \textbf{Objective:} $\min_{w,b} \frac{1}{2} \|w\|^2$
  \item \textbf{Discriminant Function:} $f(x) = w^T \phi(x) + b$
  \item \textbf{Support Vectors:} $y_i(w^T \phi(x_i) + b) = 1$
  \item \textbf{Polynomial Kernel:} $K(x, y) = (1 + \langle x, y \rangle)^d$
  \item \textbf{Gaussian RBF Kernel:} $K(x, y) = \exp\left(-\frac{\|x-y\|^2}{2\sigma^2}\right)$
\end{itemize}

\subsection*{Soft SVM}
\begin{itemize}
  \item \textbf{Objective:} $\min_{w,b,\xi} \frac{1}{2} \|w\|^2 + C \sum_{i=1}^N \xi_i$
  \item \textbf{Constraints:} $y_i(w^T \phi(x_i) + b) \geq 1 - \xi_i$
  \item \textbf{Slack Variables:} $\xi_i \geq 0$
  \item \textbf{Lagrangian:} $\mathcal{L}(w, b, \xi, \alpha, \beta) = \frac{1}{2} \|w\|^2 + C \sum_{i=1}^N \xi_i - \sum_{i=1}^N \alpha_i(y_i(w^T \phi(x_i) + b) - 1 + \xi_i) - \sum_{i=1}^N \beta_i \xi_i$
  \item \textbf{KKT Conditions:} $\alpha_i \geq 0, \beta_i \geq 0, \alpha_i(y_i(w^T \phi(x_i) + b) - 1 + \xi_i) = 0, \beta_i \xi_i = 0$
  \item \textbf{Dual Problem:} $\max_\alpha \sum_{i=1}^N \alpha_i - \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j K(x_i, x_j)$
  \item \textbf{Predictor:} $f(x) = \sum_{i=1}^N \alpha_i y_i K(x, x_i) + b$
\end{itemize}

\section*{Dimensionality Reduction}
\subsection*{Curse of Dimensionality}
\begin{itemize}
  \item \textbf{Volume:} $V_d(r) = r^d$
  \item \textbf{Ratio:} $ratio = \frac{V_{crust}}{V_{S_1}} = \frac{V_{S_1} - V_{crust}}{V_{S_1}}$
  \item \textbf{Vol Eqn:} $V = \frac{r^D \cdot \pi^{D/2}}{\rho(D/2 + 1)}$
  \item \textbf{ratio} = $1 - (1 - \frac{\epsilon}{r})^D$
\end{itemize}

\subsection*{Feature Selection}
\begin{itemize}
  \item \textbf{Embedded:} L1: $\text{L1: }\Vert\mathbf{w}\Vert_1 = \sum_{j=0}^M |w_j|$
  \item \textbf{Wrappers:} Recursive Feature Elimination using Greedy Search
  \item \textbf{Feature Extraction:} PCA, LDA
\end{itemize}

\subsubsection*{PCA:}
\begin{itemize}
  \item \textbf{Mean:} $\mu = \frac{1}{N} \sum_{i=1}^N x_i$
  \item \textbf{Covariance:} $\Sigma = \frac{1}{N} \sum_{i=1}^N (x_i - \mu)(x_i - \mu)^T$
  \item \textbf{Eigendecomposition:} $\Sigma = W \Lambda W^T$
  \item \textbf{Sorting:} $\lambda_1 \geq \lambda_2 \geq \ldots \geq \lambda_M$
  \item \textbf{Projection:} $z = W^T x$
  \item \textbf{Reconstruction:} $x = W z + \mu$
\end{itemize}

\subsection*{MDS:}
\begin{itemize}
  \item \textbf{Distance Matrix:} $D = \{d_{ij}\}$
  \item \textbf{Gram Matrix:} $G = -\frac{1}{2} H D H$
  \item \textbf{Eigendecomposition:} $G = V \Lambda V^T$
  \item \textbf{Projection:} $Z = V \Lambda^{1/2}$
  \item \textbf{Reconstruction:} $D = \{d_{ij}\}$
\end{itemize}

\subsection{ISOMAP}
\begin{itemize}
  \item \textbf{Shortest Path:} $d_{ij} = \min_{p_{ij}} \sum_{k=1}^{L_{ij}-1} \|x_{p_{ij}(k)} - x_{p_{ij}(k+1)}\|$
  \item \textbf{Time Complexity:} $O(N^3)$
\end{itemize}

\subsection*{LLE}
\begin{itemize}
  \item Finding a set of weights $W \in \Re^{D \times d}$ that minimizes the reconstruction error
  \item $x_i = \sum_{j=1}^K w_{ij} x_{i(j)}$
\end{itemize}

\subsection*{t-SNE}
\begin{itemize}
  \item \textbf{Objective:} $KL(P||Q) = \sum_i \sum_j p_{ij} \log \frac{p_{ij}}{q_{ij}}$
  \item \textbf{Perplexity:} $\text{Perp}(P_i) = 2^{H(P_i)}$
  \item \textbf{Symmetric SNE:} $p_{ij} = \frac{p_{i|j} + p_{j|i}}{2N}$
  \item \textbf{Gradient:} $\frac{\partial C}{\partial y_i} = 4 \sum_j (p_{ij} - q_{ij})(y_i - y_j)(1 + \|y_i - y_j\|^2)^{-1}$
  \item \textbf{Time Complexity:} $O(N^2)$
\end{itemize}

\section*{Clustering}

\subsection*{K-Means}
\begin{enumerate}
  \item Centroid Assignment: $u^{(i)} = \arg\min_j \|x^{(i)} - \mu_j\|^2$
  \item Requires \textbf{Scaling the Data}
  \item Convergence if Assignments do not change
\end{enumerate}


\end{multicols}

\end{document}

